# ğŸ˜ï¸ Real Estate Scraper Application â€“ Cloud-Native

A modern, production-grade backend system for scraping and storing real estate listings using Python, FastAPI, PostgreSQL, Docker, and Kubernetes. Designed with observability, CI/CD, high availability, and disaster recovery in mind.

---

## ğŸ¯ Project Goals

- Build a **scraper backend** for real estate listings (non-commercial, demo data).
- Provide an **API** for accessing and managing scraped data.
- Host with **cloud portability** in mind (AWS for now, Azure/GCP compatible).
- Ensure **resilience, scalability, and maintainability** using Docker, K8s, CI/CD, and backups.
- Serve **frontend and backend under the same domain** via a reverse proxy (nginx or ingress).

---

## ğŸ”§ Tech Stack

- **Python 3.10+**, FastAPI
- **SQLAlchemy**, PostgreSQL
- **Docker**, Docker Compose
- **GitHub Actions** (CI/CD)
- **Kubernetes** (Minikube / AWS EKS / Azure AKS / GCP GKE)
- **Prometheus + Grafana (AGPL!)** (Monitoring)
- **AWS Free Tier** (current deployment)
- Disaster Recovery & High Availability ready
- **nginx / Ingress** for serving frontend + backend on one domain

---

## ğŸ“¦ Project Structure

```
real-estate-scraper/
â”œâ”€â”€ app/                    # FastAPI backend
â”‚   â”œâ”€â”€ scrapers/           # scraping logic
â”‚   â”œâ”€â”€ models/             # SQLAlchemy models
â”‚   â”œâ”€â”€ api/                # API routes
â”œâ”€â”€ frontend/               # React frontend app
â”œâ”€â”€ tests/                  # unit & integration tests
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ kubernetes/             # K8s manifests incl. ingress
â”œâ”€â”€ .github/workflows/      # GitHub Actions CI/CD
â”œâ”€â”€ scripts/                # backup/restore scripts
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸš€ Features

- `/scrape` â€“ trigger real estate scraping task (mock or live HTML)
- `/listings` â€“ query stored listings with filters
- `/health`, `/metrics` â€“ health & metrics endpoints
- Job scheduler (optional) for recurring scrapes
- Clean separation between scraping & API layer
- React frontend served through same domain via reverse proxy

---

## ğŸ§ª DevOps & Cloud Features

- Dockerized microservice
- CI/CD pipeline (test â†’ build â†’ push â†’ deploy)
- K8s-ready manifests (`deployment.yaml`, `service.yaml`, `hpa.yaml`, `ingress.yaml`)
- Prometheus metrics & Grafana dashboard
- Backup and restore scripts for PostgreSQL
- Simulated failure scenarios (for DR testing)
- AWS deployment via EC2/EKS and S3 for backups
- Portable to Azure & GCP

---

## ğŸ›¡ï¸ High Availability & Disaster Recovery

- Replicated pods via `replicas: 2` in K8s
- Horizontal Pod Autoscaler (`hpa.yaml`)
- External database backup to S3 (`backup.sh` + cronJob)
- Simulated pod/database crash recovery guides

---

## ğŸ“ˆ Monitoring

- `/metrics` for Prometheus scraping
- Service metrics: request count, response times, uptime
- Grafana dashboard with alerts for scraper failures

---

## ğŸ§¹ Static Code Analysis (Python & React)

- `ruff` â€“ ultra-fast linter (Python, replaces flake8, black, isort, etc.)
- `mypy` â€“ static typing and type checking
- `bandit` â€“ Python security analyzer
- `eslint` â€“ JS/React/TS linter
- `prettier` â€“ auto-code formatter
- `typescript` â€“ type-safe frontend codebase

All tools are open-source and run locally or via GitHub Actions (CI/CD).

---

## ğŸ“‘ To-Do / Roadmap

- [ ] Core scraper with BeautifulSoup/Playwright/Selenium
- [ ] Asynchronous FastAPI routes
- [ ] PostgreSQL schema for listings
- [ ] Docker Compose setup
- [ ] CI pipeline with test + lint + build
- [ ] Kubernetes manifests
- [ ] AWS deployment
- [ ] DR simulation (backup & restore)
- [ ] Monitoring and metrics
- [ ] React frontend integration
- [ ] Serve frontend + backend under single domain
- [ ] Helm & Terraform support (optional)

---

## âš ï¸ Legal & Ethical Disclaimer

This project uses **mocked or publicly available HTML** for demonstration purposes. It is designed strictly for **educational use** and does **not access or store any private or proprietary data**.

---

## ğŸ“¦ Versioning and Release Notes

- We maintain a **`CHANGELOG.md`** file at the root of the repository to track all notable changes per release.
- Each release is tagged using **Semantic Versioning (MAJOR.MINOR.PATCH)**.
- GitHub **Releases** are created for every new version, linking to the changelog entries.
- Pull Requests and commit messages follow conventional commits style (`feat:`, `fix:`, etc.) to help generate changelog entries.
- This process ensures clarity and smooth collaboration in a team environment.

A link to the full changelog can be found [here](./CHANGELOG.md).

---
